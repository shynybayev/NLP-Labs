{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9v73LmOe8UH",
        "colab_type": "code",
        "outputId": "76e971a5-8668-4dd3-e148-4ce0e6700ff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "pip install python-levenshtein\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
            "\r\u001b[K     |██████▊                         | 10kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-levenshtein) (46.1.3)\n",
            "Building wheels for collected packages: python-levenshtein\n",
            "  Building wheel for python-levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-levenshtein: filename=python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl size=144810 sha256=82d485543f9dbb6ae057da36646cafb31c6d64355815e86dbf4c8d3a59ea9f46\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n",
            "Successfully built python-levenshtein\n",
            "Installing collected packages: python-levenshtein\n",
            "Successfully installed python-levenshtein-0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkA2UrNJgVlj",
        "colab_type": "code",
        "outputId": "ab7f8cc1-53cc-4519-adc4-30c6fb962670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "pip install fuzzywuzzy\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ16AbFogiZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet as wn\n",
        "import numpy as np\n",
        "from fuzzywuzzy import fuzz \n",
        "import ipywidgets as widgets\n",
        "import pprint\n",
        "from ipywidgets import interact, interact_manual\n",
        "import re\n",
        "__PATH__ = \"https://raw.githubusercontent.com/shynybayev/NLP-Labs/master/Lab7/data.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqyB_jAvg7Ak",
        "colab_type": "code",
        "outputId": "f8b283b7-a8c8-4c18-b29c-6a6f79cbea00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oha9B2tyhFPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(__PATH__,sep=\";\",header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfWqgt0KkHWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titles = list(df['title'].apply(\n",
        "    lambda t : \n",
        "        tuple(\n",
        "            filter(lambda e:not e in stopwords.words('english'),\n",
        "                map(lambda e:e.lower(),\n",
        "                       re.findall('([A-Z]{1}[a-z]+)',t.replace('.pdf','')))\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvhvJF2DK6os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = {}\n",
        "for title in titles:\n",
        "    synsets = {}\n",
        "    for word in title:\n",
        "        synsets[word]=[synset for synset in wn.synsets(word)]\n",
        "    res[title] = synsets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB8jsLFQK_uj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def distance(a, b):\n",
        "    return\n",
        "\n",
        "    \n",
        "buff = list(res.items())\n",
        "dist = np.zeros((len(buff),len(buff)))\n",
        "for lli,ll in enumerate(buff):\n",
        "    for rri,rr in enumerate(buff):\n",
        "        dist[lli,rri]=distance(ll[0],rr[0])\n",
        "dist\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJQz7YXwLMT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@interact(ind=(0,len(buff)-1,1))\n",
        "def hypernyms(ind=0):\n",
        "    pp = pprint.PrettyPrinter(indent=4)\n",
        "    print(' '.join(buff[ind][0]))\n",
        "    pp.pprint(buff[ind][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN8Pv2d0LKEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@interact(ind=(0,len(buff)-1,1))\n",
        "def hypernyms(ind=0):\n",
        "    pp = pprint.PrettyPrinter(indent=4)\n",
        "    print(' '.join(buff[ind][0]))\n",
        "    pp.pprint(buff[ind][1])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}