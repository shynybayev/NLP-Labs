{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "HypernymTitles.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMo3kj3LC3rA",
        "colab_type": "text"
      },
      "source": [
        "#### Lab 7 \n",
        "#### Rouge Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nnPP3dWKa5Y",
        "colab_type": "code",
        "outputId": "b8369975-a27c-4501-bc0e-5743376fa288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "pip install python-levenshtein\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
            "\r\u001b[K     |██████▊                         | 10kB 22.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-levenshtein) (46.1.3)\n",
            "Building wheels for collected packages: python-levenshtein\n",
            "  Building wheel for python-levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-levenshtein: filename=python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl size=144800 sha256=962e7c6fcef02abdbbe822e2d52a104b5a947ca952639f919eba07f68c7aa820\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n",
            "Successfully built python-levenshtein\n",
            "Installing collected packages: python-levenshtein\n",
            "Successfully installed python-levenshtein-0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGJvFcMvloNL",
        "colab_type": "code",
        "outputId": "6370e342-461c-4142-8ffa-17b544a2ac62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "pip install fuzzywuzzy\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obigo_n1C3rB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet as wn\n",
        "import numpy as np\n",
        "from fuzzywuzzy import fuzz \n",
        "import ipywidgets as widgets\n",
        "import pprint\n",
        "from ipywidgets import interact, interact_manual\n",
        "import re\n",
        "__PATH__ = \"https://raw.githubusercontent.com/shynybayev/NLP-Labs/master/Lab7/data.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UWQysSWC3rG",
        "colab_type": "code",
        "outputId": "b4b9dcd9-fcc4-444e-d3db-f1c2434163f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "qg2mYAm3C3rI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(__PATH__,sep=\";\",header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG1xtU4xC3rK",
        "colab_type": "text"
      },
      "source": [
        "#### Preprocessing the title to list of tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRgalGvEC3rL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titles = list(df['title'].apply(\n",
        "    lambda t : \n",
        "        tuple(\n",
        "            filter(lambda e:not e in stopwords.words('english'),\n",
        "                map(lambda e:e.lower(),\n",
        "                       re.findall('([A-Z]{1}[a-z]+)',t.replace('.pdf','')))\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojN89e-cC3rN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = {}\n",
        "for title in titles:\n",
        "    synsets = {}\n",
        "    for word in title:\n",
        "        synsets[word]=[synset for synset in wn.synsets(word)]\n",
        "    res[title] = synsets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKLFrGpZKL2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extractHprnmsEng(word):\n",
        "    synset = wn.synsets(word)\n",
        "    if len(synset) == 0 \n",
        "        return None, None\n",
        "    else:\n",
        "        for synset in wn.synsets(word):\n",
        "            for hypernym in synset.hypernyms():\n",
        "        return synset.hypernym()\n",
        "\n",
        "\n",
        "def F1Measure (a, b):\n",
        "    a = set(a)\n",
        "    b = set(b)\n",
        "    overlap = set()\n",
        "    overlap_hyp_cnt = 0\n",
        "    overlap = a.intersection(b)\n",
        "    overlap_hyp_cnt = len(overlap) \n",
        "    recall = overlap_hyp_cnt/len(a)\n",
        "    prec = overlap_hyp_cnt/len(b)\n",
        "    if len(overlap) == 0:\n",
        "        return 0, overlap\n",
        "    else:\n",
        "        return 2*recall*prec/(recall+prec), overlap\n",
        "    \n",
        "lang = 'eng'\n",
        "def distance(a,b):\n",
        "    a=set(a)\n",
        "    b=set(b)\n",
        "    f1score, overlap = F1Measure(a, b)\n",
        "    a = a-overlap\n",
        "    b = b-overlap\n",
        "    if len(a)==0 or len(b)==0:\n",
        "        return 1.0-f1score\n",
        "    collect_a= {}\n",
        "    collect_b= {}\n",
        "    collect_a1= {}\n",
        "    collect_b1= {}\n",
        "    if lang=='eng':\n",
        "        collect_a  = extractHprnmsEng(a)\n",
        "        collect_b  = extractHprnmsEng(b)\n",
        "        collect_a1  = extractHprnmsEng(collect_a)\n",
        "        collect_b1  = extractHprnmsEng(collect_b1)\n",
        "\n",
        "    overlap_hyp_cnt = 0\n",
        "    for word in a:\n",
        "        for wordb in b:\n",
        "            if len(collect_a[word].intersection(collect_b[wordb]))>0:\n",
        "                overlap_hyp_cnt +=1\n",
        "            elif len(collect_a1[word].intersection(collect_b1[wordb]))>0:\n",
        "                overlap_hyp_cnt +=0.5\n",
        "    recall_hyp = overlap_hyp_cnt/len(a)\n",
        "    prec_hyp = overlap_hyp_cnt/len(b)\n",
        "    f1score_hyp = 2*recall_hyp*prec_hyp/(recall_hyp+prec_hyp) if overlap_hyp_cnt > 0 else 0\n",
        "    f1res = (2*f1score+f1score_hyp)/3\n",
        "    return (1.0-f1res)\n",
        "        \n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ynX4Y-V5EA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lang = 'eng'\n",
        "#return float((100-fuzz.ratio(a,b))/100)\n",
        "\n",
        "buff = list(res.items())\n",
        "dist = np.zeros((len(buff),len(buff)))\n",
        "for lli,ll in enumerate(buff):\n",
        "    for rri,rr in enumerate(buff):\n",
        "        dist[lli,rri]=distance(ll[0],rr[0])\n",
        "print(dist)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnUOjMxM5A1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@interact(ind=(0,len(buff)-1,1))\n",
        "def h(ind=0):\n",
        "    pp = pprint.PrettyPrinter(indent=4)\n",
        "    print(' '.join(buff[ind][0]))\n",
        "    pp.pprint([buff[i][0] for i in dist[ind][:].argsort()[1:11]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVW9NVFmC3rR",
        "colab_type": "text"
      },
      "source": [
        "#### Top ten closest articles with fuzzy metrics of titles\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFGd35VupfXc",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJfKkP_sC3rS",
        "colab_type": "code",
        "outputId": "e3ddbefa-ea40-4464-f87b-45690e241fce",
        "colab": {
          "referenced_widgets": [
            "b06d56940d7a4b33b49ac122f8055d9d"
          ]
        }
      },
      "source": [
        "@interact(ind=(0,len(buff)-1,1))\n",
        "def h(ind=0):\n",
        "    pp = pprint.PrettyPrinter(indent=4)\n",
        "    print(' '.join(buff[ind][0]))\n",
        "    pp.pprint([buff[i][0] for i in dist[ind][:].argsort()[1:11]])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b06d56940d7a4b33b49ac122f8055d9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='ind', max=995), Output()), _dom_classes=('widget-interac…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ3fW1fSC3rU",
        "colab_type": "code",
        "outputId": "af83791b-ef9e-4c5a-bf6a-a1be03881661",
        "colab": {
          "referenced_widgets": [
            "fd9b9f3aff4a4b518fb0345303c63386"
          ]
        }
      },
      "source": [
        "@interact(ind=(0,len(buff)-1,1))\n",
        "def hypernyms(ind=0):\n",
        "    pp = pprint.PrettyPrinter(indent=4)\n",
        "    print(' '.join(buff[ind][0]))\n",
        "    pp.pprint(buff[ind][1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd9b9f3aff4a4b518fb0345303c63386",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='ind', max=995), Output()), _dom_classes=('widget-interac…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjyKDbxtC3rW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}